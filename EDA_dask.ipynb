{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f97efd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9a1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sightings_df = dd.read_csv('data/ebd_US-VT_smp_relJul-2025.txt', \n",
    "                 sep='\\t', \n",
    "                 usecols=['GLOBAL UNIQUE IDENTIFIER', 'LAST EDITED DATE', 'TAXONOMIC ORDER', 'CATEGORY', 'COMMON NAME', 'SCIENTIFIC NAME', 'OBSERVATION COUNT', 'STATE', 'COUNTY', 'COUNTY CODE', 'LOCALITY', 'LOCALITY ID', 'LOCALITY TYPE', 'LATITUDE', 'LONGITUDE', 'OBSERVATION DATE', 'TIME OBSERVATIONS STARTED', 'OBSERVER ID', 'SAMPLING EVENT IDENTIFIER', 'OBSERVATION TYPE', 'DURATION MINUTES', 'EFFORT DISTANCE KM', 'NUMBER OBSERVERS', 'ALL SPECIES REPORTED', 'GROUP IDENTIFIER'],\n",
    "                 blocksize=25e6,\n",
    "                 na_values={'OBSERVATION COUNT': 'X'},\n",
    "                 dtype={\n",
    "                        'GLOBAL UNIQUE IDENTIFIER': 'string',\n",
    "                        'LAST EDITED DATE': 'string',\n",
    "                        'TAXONOMIC ORDER': 'UInt32',\n",
    "                        'CATEGORY': 'category',\n",
    "                        'COMMON NAME': 'category',\n",
    "                        'SCIENTIFIC NAME': 'category',\n",
    "                        'OBSERVATION COUNT': 'UInt32',\n",
    "                        'STATE': 'category',\n",
    "                        'COUNTY': 'category',\n",
    "                        'COUNTY CODE': 'category',\n",
    "                        'LOCALITY': 'string',\n",
    "                        'LOCALITY ID': 'string',\n",
    "                        'LOCALITY TYPE': 'category',\n",
    "                        'LATITUDE': 'float64',\n",
    "                        'LONGITUDE': 'float64',\n",
    "                        'OBSERVATION DATE': 'period[D]',\n",
    "                        'TIME OBSERVATIONS STARTED': 'string',\n",
    "                        'OBSERVER ID': 'string',\n",
    "                        'SAMPLING EVENT IDENTIFIER': 'string',\n",
    "                        'OBSERVATION TYPE': 'category',\n",
    "                        'DURATION MINUTES': 'UInt16',\n",
    "                        'EFFORT DISTANCE KM': 'Float32',\n",
    "                        'NUMBER OBSERVERS': 'UInt8',\n",
    "                        'ALL SPECIES REPORTED': 'boolean',\n",
    "                        'GROUP IDENTIFIER': 'string',\n",
    "\n",
    "                        }\n",
    "                )\n",
    "\n",
    "sightings_df['GLOBAL UNIQUE IDENTIFIER'] = sightings_df['GLOBAL UNIQUE IDENTIFIER'].str.extract(r'(\\d+)$')[0].astype('Int64')\n",
    "sightings_df['SAMPLING EVENT IDENTIFIER'] = sightings_df['SAMPLING EVENT IDENTIFIER'].str.extract(r'(\\d+)$')[0].astype('Int64')\n",
    "sightings_df['LOCALITY ID'] = sightings_df['LOCALITY ID'].str.extract(r'(\\d+)$')[0].astype('Int64')\n",
    "sightings_df['GROUP IDENTIFIER'] = sightings_df['GROUP IDENTIFIER'].str.extract(r'(\\d+)$')[0].astype('Int64')\n",
    "sightings_df['LAST EDITED DATE'] = dd.to_datetime(sightings_df['LAST EDITED DATE'], errors='coerce')\n",
    "sightings_df = sightings_df.categorize(columns=['COMMON NAME', 'SCIENTIFIC NAME', 'COUNTY CODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42081e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.to_parquet(sightings_df, 'data/VT_observations.parquet', engine=\"pyarrow\", write_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4805f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sightings_df = dd.read_parquet('data/VT_observations.parquet', engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "825d15c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_hotspot_sightings_df = sightings_df[\n",
    "      (sightings_df['LOCALITY TYPE'] == 'H')\n",
    "    & (sightings_df['CATEGORY'] == 'species')\n",
    "    & (sightings_df['ALL SPECIES REPORTED'])\n",
    "]\n",
    "\n",
    "# print(\"Num sightings: \", len(complete_hotspot_sightings_df))\n",
    "# print(\"Num group sightings: \", complete_hotspot_sightings_df['GROUP IDENTIFIER'].count().compute())\n",
    "# print(\"Num solo sightings: \", complete_hotspot_sightings_df['GROUP IDENTIFIER'].isna().sum().compute())\n",
    "\n",
    "# REMOVE DUPLICATE ROWS FROM GROUP CHECKLISTS \n",
    "\n",
    "# not sure why this logic isn't working, fix later, workaround below\n",
    "# unique_complete_hotspot_sightings_df = complete_hotspot_sightings_df.drop_duplicates(subset=['GROUP IDENTIFIER'], split_every=False)\n",
    "\n",
    "solo_sightings_df = complete_hotspot_sightings_df[complete_hotspot_sightings_df['GROUP IDENTIFIER'].isna()]\n",
    "group_sightings_df = complete_hotspot_sightings_df[complete_hotspot_sightings_df['GROUP IDENTIFIER'].notnull()]\n",
    "group_sightings_df = group_sightings_df.sort_values('SAMPLING EVENT IDENTIFIER')\n",
    "group_sightings_df = group_sightings_df.drop_duplicates(subset=['GROUP IDENTIFIER', 'COMMON NAME'])\n",
    "\n",
    "unique_complete_hotspot_sightings_df = dd.concat([solo_sightings_df, group_sightings_df])\n",
    "# print(\"Num solo sightings: \", unique_complete_hotspot_sightings_df['GROUP IDENTIFIER'].isna().sum().compute())\n",
    "# print(\"Num species: \", unique_complete_hotspot_sightings_df['COMMON NAME'].nunique().compute())\n",
    "# print(\"Num hotspots: \", unique_complete_hotspot_sightings_df['LOCALITY ID'].nunique().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47571810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249494\n"
     ]
    }
   ],
   "source": [
    "print(unique_complete_hotspot_sightings_df['SAMPLING EVENT IDENTIFIER'].nunique().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd6d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "checklists_df = dd.read_csv('data/ebd_US-VT_smp_relJul-2025_sampling.txt',\n",
    "                        sep='\\t', \n",
    "                        blocksize=25e6,\n",
    "                        usecols=['LAST EDITED DATE', 'OBSERVATION DATE', 'LOCALITY', 'LOCALITY ID', 'LOCALITY TYPE', 'SAMPLING EVENT IDENTIFIER', 'OBSERVATION TYPE', 'DURATION MINUTES', 'EFFORT DISTANCE KM', 'NUMBER OBSERVERS', 'ALL SPECIES REPORTED', 'GROUP IDENTIFIER'],\n",
    "                        dtype={\n",
    "                            'LAST EDITED DATE': 'string',\n",
    "                            'OBSERVATION DATE': 'period[D]',\n",
    "                            'LOCALITY': 'string',\n",
    "                            'LOCALITY ID': 'string',\n",
    "                            'LOCALITY TYPE': 'category',\n",
    "                            'SAMPLING EVENT IDENTIFIER': 'string',\n",
    "                            'OBSERVATION TYPE': 'category',\n",
    "                            'DURATION MINUTES': 'UInt16',\n",
    "                            'EFFORT DISTANCE KM': 'Float32',\n",
    "                            'NUMBER OBSERVERS': 'UInt8',\n",
    "                            'ALL SPECIES REPORTED': 'boolean',\n",
    "                            'GROUP IDENTIFIER': 'string'\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "checklists_df['LAST EDITED DATE'] = dd.to_datetime(checklists_df['LAST EDITED DATE'], errors='coerce')\n",
    "checklists_df['LOCALITY ID'] = checklists_df['LOCALITY ID'].str.extract(r'(\\d+)$')[0].astype('Int64')\n",
    "checklists_df['SAMPLING EVENT IDENTIFIER'] = checklists_df['SAMPLING EVENT IDENTIFIER'].str.extract(r'(\\d+)$')[0].astype('Int64')\n",
    "sightings_df['GROUP IDENTIFIER'] = sightings_df['GROUP IDENTIFIER'].str.extract(r'(\\d+)$')[0].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd90052",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.to_parquet(checklists_df, 'data/VT_checklists.parquet', engine=\"pyarrow\", write_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf86360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checklists_df = dd.read_parquet('data/VT_checklists.parquet', engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7effeb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_hotspot_checklists_df = checklists_df[\n",
    "      (checklists_df['ALL SPECIES REPORTED'])\n",
    "    & (checklists_df['LOCALITY TYPE'] == 'H')\n",
    "]\n",
    "\n",
    "solo_checklists_df = complete_hotspot_checklists_df[complete_hotspot_checklists_df['GROUP IDENTIFIER'].isna()]\n",
    "group_checklists_df = complete_hotspot_checklists_df[complete_hotspot_checklists_df['GROUP IDENTIFIER'].notnull()]\n",
    "group_checklists_df = group_checklists_df.sort_values('SAMPLING EVENT IDENTIFIER')\n",
    "unique_group_checklists_df = group_checklists_df.drop_duplicates(subset=['GROUP IDENTIFIER'])\n",
    "unique_complete_hotspot_checklists_df = dd.concat([solo_checklists_df, unique_group_checklists_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7051e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count total checklists per day at each hotspot\n",
    "total_checklists_per_day_df = (\n",
    "    unique_complete_hotspot_checklists_df\n",
    "    .groupby(['LOCALITY ID', 'OBSERVATION DATE'], observed=True)\n",
    "    .size()\n",
    "    .rename('TOTAL CHECKLISTS')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "total_sightings_per_day_df = (\n",
    "    unique_complete_hotspot_sightings_df\n",
    "    .groupby(['LOCALITY ID', 'OBSERVATION DATE', 'COMMON NAME'], observed=True)\n",
    "    ['SAMPLING EVENT IDENTIFIER']\n",
    "    .nunique()\n",
    "    .rename('TOTAL SIGHTINGS')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "abundance_df = total_sightings_per_day_df.merge(\n",
    "    total_checklists_per_day_df,\n",
    "    on=['LOCALITY ID', 'OBSERVATION DATE'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d729553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(total_checklists_per_day_df))\n",
    "print(len(total_sightings_per_day_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d7dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abundance_df['TOTAL CHECKLISTS'].value_counts().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c8249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "abundance_df['COMMON NAME'] = abundance_df['COMMON NAME'].cat.as_known()\n",
    "abundance_df['TOTAL CHECKLISTS'] = abundance_df['TOTAL CHECKLISTS'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631d945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "abundance_df['ABUNDANCE'] = abundance_df['TOTAL SIGHTINGS'] / abundance_df['TOTAL CHECKLISTS']\n",
    "abundance_df['DAY OF YEAR'] = abundance_df['OBSERVATION DATE'].dt.dayofyear\n",
    "\n",
    "mean_abundance_df = (\n",
    "    abundance_df\n",
    "    .groupby(['LOCALITY ID', 'COMMON NAME', 'DAY OF YEAR'], observed=True)\n",
    "    ['ABUNDANCE']\n",
    "    .mean()\n",
    "    .rename('MEAN ABUNDANCE')\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2e4541",
   "metadata": {},
   "outputs": [],
   "source": [
    "abundance_df.to_parquet('data/VT_abundance.parquet', engine=\"pyarrow\", write_index=False)\n",
    "mean_abundance_df.to_parquet('data/VT_mean_abundance.parquet', engine=\"pyarrow\", write_index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
