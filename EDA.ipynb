{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97efd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9b9a1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sightings_df = dd.read_csv('data/ebd_US-VT_smp_relJul-2025.txt', \n",
    "                 sep='\\t', \n",
    "                 usecols=['GLOBAL UNIQUE IDENTIFIER', 'LAST EDITED DATE', 'TAXONOMIC ORDER', 'CATEGORY', 'COMMON NAME', 'SCIENTIFIC NAME', 'OBSERVATION COUNT', 'STATE', 'COUNTY', 'COUNTY CODE', 'LOCALITY', 'LOCALITY ID', 'LOCALITY TYPE', 'LATITUDE', 'LONGITUDE', 'OBSERVATION DATE', 'TIME OBSERVATIONS STARTED', 'OBSERVER ID', 'SAMPLING EVENT IDENTIFIER', 'OBSERVATION TYPE', 'DURATION MINUTES', 'EFFORT DISTANCE KM', 'NUMBER OBSERVERS', 'ALL SPECIES REPORTED', 'GROUP IDENTIFIER'],\n",
    "                 blocksize=25e6,\n",
    "                 na_values={'OBSERVATION COUNT': 'X'},\n",
    "                 dtype={\n",
    "                        'GLOBAL UNIQUE IDENTIFIER': 'string',\n",
    "                        'LAST EDITED DATE': 'string',\n",
    "                        'TAXONOMIC ORDER': 'UInt32',\n",
    "                        'CATEGORY': 'category',\n",
    "                        'COMMON NAME': 'category',\n",
    "                        'SCIENTIFIC NAME': 'category',\n",
    "                        'OBSERVATION COUNT': 'UInt32',\n",
    "                        'STATE': 'category',\n",
    "                        'COUNTY': 'category',\n",
    "                        'COUNTY CODE': 'category',\n",
    "                        'LOCALITY': 'string',\n",
    "                        'LOCALITY ID': 'string',\n",
    "                        'LOCALITY TYPE': 'category',\n",
    "                        'LATITUDE': 'float64',\n",
    "                        'LONGITUDE': 'float64',\n",
    "                        'OBSERVATION DATE': 'period[D]',\n",
    "                        'TIME OBSERVATIONS STARTED': 'string',\n",
    "                        'OBSERVER ID': 'string',\n",
    "                        'SAMPLING EVENT IDENTIFIER': 'string',\n",
    "                        'OBSERVATION TYPE': 'category',\n",
    "                        'DURATION MINUTES': 'UInt16',\n",
    "                        'EFFORT DISTANCE KM': 'Float32',\n",
    "                        'NUMBER OBSERVERS': 'UInt8',\n",
    "                        'ALL SPECIES REPORTED': 'boolean',\n",
    "                        'GROUP IDENTIFIER': 'string',\n",
    "\n",
    "                        }\n",
    "                )\n",
    "\n",
    "sightings_df['GLOBAL UNIQUE IDENTIFIER'] = sightings_df['GLOBAL UNIQUE IDENTIFIER'].str.extract(r'(\\d+)$')[0].astype('Int64')\n",
    "sightings_df['SAMPLING EVENT IDENTIFIER'] = sightings_df['SAMPLING EVENT IDENTIFIER'].str.extract(r'(\\d+)$')[0].astype('Int64')\n",
    "sightings_df['LOCALITY ID'] = sightings_df['LOCALITY ID'].str.extract(r'(\\d+)$')[0].astype('Int64')\n",
    "sightings_df['GROUP IDENTIFIER'] = sightings_df['GROUP IDENTIFIER'].str.extract(r'(\\d+)$')[0].astype('Int64')\n",
    "sightings_df['LAST EDITED DATE'] = dd.to_datetime(sightings_df['LAST EDITED DATE'], errors='coerce')\n",
    "sightings_df = sightings_df.categorize(columns=['COMMON NAME', 'SCIENTIFIC NAME', 'COUNTY CODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "42081e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.to_parquet(sightings_df, 'data/VT_observations.parquet', engine=\"pyarrow\", write_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4805f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sightings_df = dd.read_parquet('data/VT_observations.parquet', engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825d15c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num species:  352\n",
      "Num hotspots:  1399\n"
     ]
    }
   ],
   "source": [
    "complete_hotspot_sightings_df = sightings_df[\n",
    "      (sightings_df['LOCALITY TYPE'] == 'H')\n",
    "    & (sightings_df['CATEGORY'] == 'species')\n",
    "    & (sightings_df['ALL SPECIES REPORTED'])\n",
    "]\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# print(\"Num sightings: \", len(complete_hotspot_sightings_df))\n",
    "# print(\"Num group sightings: \", complete_hotspot_sightings_df['GROUP IDENTIFIER'].count().compute())\n",
    "# print(\"Num solo sightings: \", complete_hotspot_sightings_df['GROUP IDENTIFIER'].isna().sum().compute())\n",
    "\n",
    "# REMOVE DUPLICATE ROWS FROM GROUP CHECKLISTS \n",
    "\n",
    "# not sure why this logic isn't working, fix later, workaround below\n",
    "# unique_complete_hotspot_sightings_df = complete_hotspot_sightings_df.drop_duplicates(subset=['GROUP IDENTIFIER'], split_every=False)\n",
    "\n",
    "solo_sightings_df = complete_hotspot_sightings_df[complete_hotspot_sightings_df['GROUP IDENTIFIER'].isna()]\n",
    "group_sightings_df = complete_hotspot_sightings_df[complete_hotspot_sightings_df['GROUP IDENTIFIER'].notnull()]\n",
    "group_sightings_df = group_sightings_df.drop_duplicates(subset=['GROUP IDENTIFIER', 'COMMON NAME'])\n",
    "\n",
    "unique_complete_hotspot_sightings_df = dd.concat([solo_sightings_df, group_sightings_df])\n",
    "# print(\"Num unique sightings: \", len(unique_complete_hotspot_sightings_df))\n",
    "# print(\"Num solo sightings: \", unique_complete_hotspot_sightings_df['GROUP IDENTIFIER'].isna().sum().compute())\n",
    "# print(\"Num species: \", unique_complete_hotspot_sightings_df['COMMON NAME'].nunique().compute())\n",
    "# print(\"Num hotspots: \", unique_complete_hotspot_sightings_df['LOCALITY ID'].nunique().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fd6d526",
   "metadata": {},
   "outputs": [],
   "source": [
    "checklists_df = dd.read_csv('data/ebd_US-VT_smp_relJul-2025_sampling.txt',\n",
    "                        sep='\\t', \n",
    "                        blocksize=25e6,\n",
    "                        usecols=['LAST EDITED DATE', 'OBSERVATION DATE', 'LOCALITY', 'LOCALITY ID', 'LOCALITY TYPE', 'SAMPLING EVENT IDENTIFIER', 'OBSERVATION TYPE', 'DURATION MINUTES', 'EFFORT DISTANCE KM', 'NUMBER OBSERVERS', 'ALL SPECIES REPORTED', 'GROUP IDENTIFIER'],\n",
    "                        dtype={\n",
    "                            'LAST EDITED DATE': 'string',\n",
    "                            'LOCALITY': 'string',\n",
    "                            'LOCALITY ID': 'string',\n",
    "                            'LOCALITY TYPE': 'category',\n",
    "                            'SAMPLING EVENT IDENTIFIER': 'string',\n",
    "                            'OBSERVATION TYPE': 'category',\n",
    "                            'DURATION MINUTES': 'UInt16',\n",
    "                            'EFFORT DISTANCE KM': 'Float32',\n",
    "                            'NUMBER OBSERVERS': 'UInt8',\n",
    "                            'ALL SPECIES REPORTED': 'boolean',\n",
    "                            'GROUP IDENTIFIER': 'string'\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "checklists_df['LAST EDITED DATE'] = dd.to_datetime(checklists_df['LAST EDITED DATE'], errors='coerce')\n",
    "checklists_df['LOCALITY ID'] = checklists_df['LOCALITY ID'].str.extract(r'(\\d+)$')[0].astype('Int64')\n",
    "checklists_df['SAMPLING EVENT IDENTIFIER'] = checklists_df['SAMPLING EVENT IDENTIFIER'].str.extract(r'(\\d+)$')[0].astype('Int64')\n",
    "sightings_df['GROUP IDENTIFIER'] = sightings_df['GROUP IDENTIFIER'].str.extract(r'(\\d+)$')[0].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dd90052",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.to_parquet(checklists_df, 'data/VT_checklists.parquet', engine=\"pyarrow\", write_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf86360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checklists_df = dd.read_parquet('data/VT_checklists.parquet', engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7effeb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_hotspot_checklists_df = checklists_df[\n",
    "      (checklists_df['ALL SPECIES REPORTED'])\n",
    "    & (checklists_df['LOCALITY TYPE'] == 'H')\n",
    "]\n",
    "\n",
    "solo_checklists_df = complete_hotspot_checklists_df[complete_hotspot_checklists_df['GROUP IDENTIFIER'].isna()]\n",
    "group_checklists_df = complete_hotspot_checklists_df[complete_hotspot_checklists_df['GROUP IDENTIFIER'].notnull()]\n",
    "unique_group_checklists_df = group_checklists_df.drop_duplicates(subset=['GROUP IDENTIFIER'])\n",
    "unique_complete_hotspot_checklists_df = dd.concat([solo_checklists_df, unique_group_checklists_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32c252e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAST EDITED DATE</th>\n",
       "      <th>LOCALITY</th>\n",
       "      <th>LOCALITY ID</th>\n",
       "      <th>LOCALITY TYPE</th>\n",
       "      <th>OBSERVATION DATE</th>\n",
       "      <th>SAMPLING EVENT IDENTIFIER</th>\n",
       "      <th>OBSERVATION TYPE</th>\n",
       "      <th>DURATION MINUTES</th>\n",
       "      <th>EFFORT DISTANCE KM</th>\n",
       "      <th>NUMBER OBSERVERS</th>\n",
       "      <th>ALL SPECIES REPORTED</th>\n",
       "      <th>GROUP IDENTIFIER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-26 10:18:02.301179</td>\n",
       "      <td>Fairfield Swamp WMA</td>\n",
       "      <td>1140162</td>\n",
       "      <td>H</td>\n",
       "      <td>2025-05-26</td>\n",
       "      <td>242975716</td>\n",
       "      <td>Traveling</td>\n",
       "      <td>10</td>\n",
       "      <td>0.259</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-06-13 07:31:20.354768</td>\n",
       "      <td>Fairfield Swamp WMA</td>\n",
       "      <td>1140162</td>\n",
       "      <td>H</td>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>249781342</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>7</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-05-22 15:46:54.167567</td>\n",
       "      <td>Fairfield Swamp WMA</td>\n",
       "      <td>1140162</td>\n",
       "      <td>H</td>\n",
       "      <td>2025-05-22</td>\n",
       "      <td>241308832</td>\n",
       "      <td>Stationary</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-06-07 13:00:07.255729</td>\n",
       "      <td>Fairfield Swamp WMA</td>\n",
       "      <td>1140162</td>\n",
       "      <td>H</td>\n",
       "      <td>2025-05-19</td>\n",
       "      <td>240407756</td>\n",
       "      <td>Traveling</td>\n",
       "      <td>30</td>\n",
       "      <td>0.139</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-08-08 03:20:40.611660</td>\n",
       "      <td>Fairfield Swamp WMA</td>\n",
       "      <td>1140162</td>\n",
       "      <td>H</td>\n",
       "      <td>2025-03-21</td>\n",
       "      <td>219770714</td>\n",
       "      <td>Traveling</td>\n",
       "      <td>6</td>\n",
       "      <td>0.127</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            LAST EDITED DATE             LOCALITY  LOCALITY ID LOCALITY TYPE OBSERVATION DATE  SAMPLING EVENT IDENTIFIER OBSERVATION TYPE  DURATION MINUTES  EFFORT DISTANCE KM  NUMBER OBSERVERS  ALL SPECIES REPORTED GROUP IDENTIFIER\n",
       "3 2025-05-26 10:18:02.301179  Fairfield Swamp WMA      1140162             H       2025-05-26                  242975716        Traveling                10               0.259                 1                  True             <NA>\n",
       "4 2025-06-13 07:31:20.354768  Fairfield Swamp WMA      1140162             H       2025-06-13                  249781342       Stationary                 7                <NA>                 1                  True             <NA>\n",
       "5 2025-05-22 15:46:54.167567  Fairfield Swamp WMA      1140162             H       2025-05-22                  241308832       Stationary                10                <NA>                 1                  True             <NA>\n",
       "6 2025-06-07 13:00:07.255729  Fairfield Swamp WMA      1140162             H       2025-05-19                  240407756        Traveling                30               0.139                 1                  True             <NA>\n",
       "7 2025-08-08 03:20:40.611660  Fairfield Swamp WMA      1140162             H       2025-03-21                  219770714        Traveling                 6               0.127                 1                  True             <NA>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_complete_hotspot_checklists_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dcd7d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       GLOBAL UNIQUE IDENTIFIER           LAST EDITED DATE  TAXONOMIC ORDER CATEGORY          COMMON NAME       SCIENTIFIC NAME  OBSERVATION COUNT    STATE    COUNTY COUNTY CODE             LOCALITY  LOCALITY ID LOCALITY TYPE   LATITUDE  LONGITUDE OBSERVATION DATE TIME OBSERVATIONS STARTED  OBSERVER ID  SAMPLING EVENT IDENTIFIER OBSERVATION TYPE  DURATION MINUTES  EFFORT DISTANCE KM  NUMBER OBSERVERS  ALL SPECIES REPORTED GROUP IDENTIFIER\n",
      "5946                 3213453148 2025-05-26 10:18:02.301179            32338  species   American Goldfinch        Spinus tristis                  2  Vermont  Franklin   US-VT-011  Fairfield Swamp WMA      1140162             H  44.795556 -72.996275       2025-05-26                  10:06:00  obsr2046614                  242975716        Traveling                10               0.259                 1                  True             <NA>\n",
      "10676                3213453147 2025-05-26 10:18:02.301179              330  species         Canada Goose     Branta canadensis                  4  Vermont  Franklin   US-VT-011  Fairfield Swamp WMA      1140162             H  44.795556 -72.996275       2025-05-26                  10:06:00  obsr2046614                  242975716        Traveling                10               0.259                 1                  True             <NA>\n",
      "13010                3213453142 2025-05-26 10:18:02.301179            33749  species  Common Yellowthroat    Geothlypis trichas                  1  Vermont  Franklin   US-VT-011  Fairfield Swamp WMA      1140162             H  44.795556 -72.996275       2025-05-26                  10:06:00  obsr2046614                  242975716        Traveling                10               0.259                 1                  True             <NA>\n",
      "13751                3213453149 2025-05-26 10:18:02.301179            17302  species     Eastern Kingbird     Tyrannus tyrannus                  1  Vermont  Franklin   US-VT-011  Fairfield Swamp WMA      1140162             H  44.795556 -72.996275       2025-05-26                  10:06:00  obsr2046614                  242975716        Traveling                10               0.259                 1                  True             <NA>\n",
      "16123                3213453152 2025-05-26 10:18:02.301179            32034  species          House Finch  Haemorhous mexicanus                  1  Vermont  Franklin   US-VT-011  Fairfield Swamp WMA      1140162             H  44.795556 -72.996275       2025-05-26                  10:06:00  obsr2046614                  242975716        Traveling                10               0.259                 1                  True             <NA>\n",
      "16356                3213453143 2025-05-26 10:18:02.301179            26942  species  Northern House Wren     Troglodytes aedon                  1  Vermont  Franklin   US-VT-011  Fairfield Swamp WMA      1140162             H  44.795556 -72.996275       2025-05-26                  10:06:00  obsr2046614                  242975716        Traveling                10               0.259                 1                  True             <NA>\n",
      "18649                3213453150 2025-05-26 10:18:02.301179             7737  species               Osprey     Pandion haliaetus                  1  Vermont  Franklin   US-VT-011  Fairfield Swamp WMA      1140162             H  44.795556 -72.996275       2025-05-26                  10:06:00  obsr2046614                  242975716        Traveling                10               0.259                 1                  True             <NA>\n",
      "19880                3213453145 2025-05-26 10:18:02.301179            19067  species       Red-eyed Vireo       Vireo olivaceus                  1  Vermont  Franklin   US-VT-011  Fairfield Swamp WMA      1140162             H  44.795556 -72.996275       2025-05-26                  10:06:00  obsr2046614                  242975716        Traveling                10               0.259                 1                  True             <NA>\n",
      "22635                3213453151 2025-05-26 10:18:02.301179            33033  species        Swamp Sparrow   Melospiza georgiana                  1  Vermont  Franklin   US-VT-011  Fairfield Swamp WMA      1140162             H  44.795556 -72.996275       2025-05-26                  10:06:00  obsr2046614                  242975716        Traveling                10               0.259                 1                  True             <NA>\n",
      "22845                3213453144 2025-05-26 10:18:02.301179            23834  species         Tree Swallow   Tachycineta bicolor                  1  Vermont  Franklin   US-VT-011  Fairfield Swamp WMA      1140162             H  44.795556 -72.996275       2025-05-26                  10:06:00  obsr2046614                  242975716        Traveling                10               0.259                 1                  True             <NA>\n",
      "24868                3213453146 2025-05-26 10:18:02.301179            16785  species    Willow Flycatcher    Empidonax traillii                  1  Vermont  Franklin   US-VT-011  Fairfield Swamp WMA      1140162             H  44.795556 -72.996275       2025-05-26                  10:06:00  obsr2046614                  242975716        Traveling                10               0.259                 1                  True             <NA>\n"
     ]
    }
   ],
   "source": [
    "print(unique_complete_hotspot_sightings_df[(unique_complete_hotspot_sightings_df['SAMPLING EVENT IDENTIFIER'] == 242975716)].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "58f82fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       GLOBAL UNIQUE IDENTIFIER           LAST EDITED DATE  TAXONOMIC ORDER CATEGORY                   COMMON NAME      SCIENTIFIC NAME  OBSERVATION COUNT    STATE      COUNTY COUNTY CODE                              LOCALITY  LOCALITY ID LOCALITY TYPE   LATITUDE  LONGITUDE OBSERVATION DATE TIME OBSERVATIONS STARTED OBSERVER ID  SAMPLING EVENT IDENTIFIER OBSERVATION TYPE  DURATION MINUTES  EFFORT DISTANCE KM  NUMBER OBSERVERS  ALL SPECIES REPORTED GROUP IDENTIFIER\n",
      "37453                  73594045 2024-03-28 12:37:52.711441            33576  species                Common Grackle   Quiscalus quiscula                  4  Vermont     Addison   US-VT-001                        Hurd Grassland       763439             H  44.022138 -73.185532       2009-07-09                  09:25:00  obsr193007                    5235801        Traveling                65               1.287                 3                  True             <NA>\n",
      "57881                  92691200 2024-04-25 20:23:03.620583            32935  species                Vesper Sparrow  Pooecetes gramineus                  1  Vermont    Franklin   US-VT-011        Franklin Co. State Airport IBA       165273             H  44.939800 -73.097800       2010-05-22                  12:15:00   obsr93349                    6450360       Incidental              <NA>                <NA>                 1                  True             <NA>\n",
      "63997                 128007525 2024-04-25 22:05:41.151370            26777  species                 Brown Creeper    Certhia americana                  1  Vermont  Washington   US-VT-023  Berlin Pond IBA - Berlin (293 acres)       150998             H  44.189920 -72.587512       2011-10-10                  07:45:00  obsr173938                    8946633        Traveling                75               0.322                 2                  True             <NA>\n",
      "44463                 149787394 2024-04-25 12:39:43.828094            33500  species          Red-winged Blackbird  Agelaius phoeniceus                 12  Vermont  Washington   US-VT-023  Berlin Pond IBA - Berlin (293 acres)       150998             H  44.189920 -72.587512       2012-04-25                  08:10:00   obsr20764                   10542688        Traveling               180               8.851                 1                  True             <NA>\n",
      "20339                 151096534 2018-08-04 15:33:17.000000            33928  species  Black-throated Green Warbler     Setophaga virens                  1  Vermont      Orange   US-VT-017    Twin Ponds - Brookfield (16 acres)       752221             H  44.061385 -72.578009       2012-05-04                  09:00:00  obsr139783                   10627995        Traveling                30               0.402                 1                  True             <NA>\n"
     ]
    }
   ],
   "source": [
    "test = (\n",
    "    unique_complete_hotspot_sightings_df.sample(frac=0.00003)\n",
    ")\n",
    "print(test.compute().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb4624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCALITY ID\n",
      "207476      1\n",
      "1968091     1\n",
      "969514      1\n",
      "752221      1\n",
      "751927      2\n",
      "           ..\n",
      "25111750    1\n",
      "11554935    1\n",
      "2385366     1\n",
      "601176      1\n",
      "2021044     2\n",
      "Name: SAMPLING EVENT IDENTIFIER, Length: 65, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test.groupby('LOCALITY ID', 'COMMON NAME', )['SAMPLING EVENT IDENTIFIER'].nunique().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7051e708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LOCALITY ID         LOCALITY OBSERVATION DATE  TOTAL CHECKLISTS\n",
      "0        71373  Putney Mountain       2011-06-04                 1\n",
      "1        71373  Putney Mountain       2016-09-21                 2\n",
      "2        71373  Putney Mountain       2018-09-24                 2\n",
      "3        71373  Putney Mountain       2023-11-13                 1\n",
      "4        71373  Putney Mountain       2025-07-12                 1\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 601. MiB for an array with shape (78821880,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[100]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     10\u001b[39m total_sightings_per_day_df = (\n\u001b[32m     11\u001b[39m     unique_complete_hotspot_sightings_df\n\u001b[32m     12\u001b[39m     .groupby([\u001b[33m'\u001b[39m\u001b[33mLOCALITY ID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mOBSERVATION DATE\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCOMMON NAME\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     .reset_index()\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(total_checklists_per_day_df.head())\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtotal_sightings_per_day_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# print(total_checklists_per_day_df['TOTAL CHECKLISTS'].value_counts().compute().sort_values(ascending=False))\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# print(total_checklists_per_day_df[(total_checklists_per_day_df['TOTAL CHECKLISTS'] > 15)].compute().sort_values(by=['TOTAL CHECKLISTS'], ascending=False))\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# print(total_sightings_per_day_df.head().compute())\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nickk\\Github\\listr\\.venv\\Lib\\site-packages\\dask\\dataframe\\dask_expr\\_collection.py:692\u001b[39m, in \u001b[36mFrameBase.head\u001b[39m\u001b[34m(self, n, npartitions, compute)\u001b[39m\n\u001b[32m    690\u001b[39m out = new_collection(expr.Head(\u001b[38;5;28mself\u001b[39m, n=n, npartitions=npartitions))\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compute:\n\u001b[32m--> \u001b[39m\u001b[32m692\u001b[39m     out = \u001b[43mout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nickk\\Github\\listr\\.venv\\Lib\\site-packages\\dask\\base.py:373\u001b[39m, in \u001b[36mDaskMethodsMixin.compute\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m    350\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[32m    351\u001b[39m \n\u001b[32m    352\u001b[39m \u001b[33;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    371\u001b[39m \u001b[33;03m    dask.compute\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     (result,) = \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nickk\\Github\\listr\\.venv\\Lib\\site-packages\\dask\\base.py:681\u001b[39m, in \u001b[36mcompute\u001b[39m\u001b[34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[39m\n\u001b[32m    678\u001b[39m     expr = expr.optimize()\n\u001b[32m    679\u001b[39m     keys = \u001b[38;5;28mlist\u001b[39m(flatten(expr.__dask_keys__()))\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m     results = \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m repack(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nickk\\Github\\listr\\.venv\\Lib\\site-packages\\dask\\dataframe\\dask_expr\\_groupby.py:302\u001b[39m, in \u001b[36mSingleAggregation.chunk\u001b[39m\u001b[34m(cls, df, *by, **kwargs)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchunk\u001b[39m(\u001b[38;5;28mcls\u001b[39m, df, *by, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nickk\\Github\\listr\\.venv\\Lib\\site-packages\\dask\\dataframe\\groupby.py:345\u001b[39m, in \u001b[36m_apply_chunk\u001b[39m\u001b[34m(df, dropna, observed, *by, **kwargs)\u001b[39m\n\u001b[32m    343\u001b[39m g = _groupby_raise_unaligned(df, by=by, **observed, **dropna)\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_series_like(df) \u001b[38;5;129;01mor\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(columns, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mset\u001b[39m, pd.Index)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nickk\\Github\\listr\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/properties.pyx:36\u001b[39m, in \u001b[36mpandas._libs.properties.CachedProperty.__get__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nickk\\Github\\listr\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:1714\u001b[39m, in \u001b[36mMultiIndex.is_monotonic_increasing\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1709\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1711\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(level.is_monotonic_increasing \u001b[38;5;28;01mfor\u001b[39;00m level \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.levels):\n\u001b[32m   1712\u001b[39m     \u001b[38;5;66;03m# If each level is sorted, we can operate on the codes directly. GH27495\u001b[39;00m\n\u001b[32m   1713\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m libalgos.is_lexsorted(\n\u001b[32m-> \u001b[39m\u001b[32m1714\u001b[39m         [\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mint64\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.codes]\n\u001b[32m   1715\u001b[39m     )\n\u001b[32m   1717\u001b[39m \u001b[38;5;66;03m# reversed() because lexsort() wants the most significant key last.\u001b[39;00m\n\u001b[32m   1718\u001b[39m values = [\n\u001b[32m   1719\u001b[39m     \u001b[38;5;28mself\u001b[39m._get_level_values(i)._values \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.levels)))\n\u001b[32m   1720\u001b[39m ]\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 601. MiB for an array with shape (78821880,) and data type int64"
     ]
    }
   ],
   "source": [
    "# count total checklists per day at each hotspot\n",
    "total_checklists_per_day_df = (\n",
    "    unique_complete_hotspot_checklists_df\n",
    "    .groupby(['LOCALITY ID', 'LOCALITY', 'OBSERVATION DATE'])\n",
    "    .size()\n",
    "    .rename('TOTAL CHECKLISTS')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "total_sightings_per_day_df = (\n",
    "    unique_complete_hotspot_sightings_df\n",
    "    .groupby(['LOCALITY ID', 'OBSERVATION DATE', 'COMMON NAME'])\n",
    "    .size()\n",
    "    .rename('TOTAL SIGHTINGS')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(total_checklists_per_day_df.head())\n",
    "print(total_sightings_per_day_df.head())\n",
    "# print(total_checklists_per_day_df['TOTAL CHECKLISTS'].value_counts().compute().sort_values(ascending=False))\n",
    "# print(total_checklists_per_day_df[(total_checklists_per_day_df['TOTAL CHECKLISTS'] > 15)].compute().sort_values(by=['TOTAL CHECKLISTS'], ascending=False))\n",
    "# print(total_sightings_per_day_df.head().compute())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
